import json
import re
from typing import List, Dict, Tuple, Optional
from src.state import QAState
from src.utils import call_llm
from src.prompts import (
    PLANNER_SYS, ANSWER_SYS, 
    get_replan_prompt, get_synthesize_prompt, get_verify_evidence_prompt,
    get_step_answer_prompt, get_select_doc_prompt, get_extractor_prompt,
    get_final_answer_prompt
)

# ==========================================
# [1] Planner Agent
# ==========================================
def node_planner(state: QAState) -> QAState:
    """
    Planner Agent: ê³„íš ìˆ˜ë¦½ ë° ìˆ˜ì • (ê°œì„  ë²„ì „)
    """
    
    # ì´ˆê¸° ê³„íš
    if not state.get("plan"):
        print("\nğŸ§  [Planner] ì´ˆê¸° ê³„íš ìˆ˜ë¦½...")
        
        q = state["question"]
        out = call_llm(PLANNER_SYS, f"Question:\n{q}\nReturn JSON only.")
        
        try:
            out_clean = out.strip()
            if out_clean.startswith("```"):
                lines = out_clean.split("\n")
                out_clean = "\n".join(lines[1:-1])
            
            j = json.loads(out_clean)
            plan = j.get("plan", [])
        except Exception as e:
            print(f"   âš ï¸ JSON parsing error: {e}")
            plan = ["Find information to answer the question."]
        
        state["plan"] = plan[:3] if plan else ["Find information to answer the question."]
        state["step_idx"] = 0
        state["planner_status"] = "active"
        state["replan_count"] = 0
        state["total_iterations"] = 0
        state["preserved_findings"] = []  #  ì¤‘ìš” ì •ë³´ ë³´ì¡´
        
        print(f"\nâœ… ì´ˆê¸° ê³„íš ({len(state['plan'])} steps):")
        for i, step in enumerate(state["plan"], 1):
            print(f"   Step {i}: {step}")
        
        state["action"] = "reasoner"
        return state
    
    # ì¬ê³„íš ìš”ì²­ ì²˜ë¦¬
    if state.get("reasoner_request") == "replan":
        replan_count = state.get("replan_count", 0)
        
        if replan_count > 2:
            print(f"\nâš ï¸ [Planner] ì¬ê³„íš í•œê³„ ë„ë‹¬ ({replan_count}ë²ˆ)")
            print(f"   â†’ ìˆ˜ì§‘í•œ ì •ë³´ë¡œ ë‹µë³€ ì‹œë„")
            state["action"] = "finish"
            return state
        
        print(f"\nğŸ”„ [Planner] ì¬ê³„íš ìš”ì²­ ë°›ìŒ! ({replan_count }/2)")
        
        # ğŸ†• ì¤‘ìš” ì •ë³´ ì¶”ì¶œ ë° ë³´ì¡´
        progress = state.get("step_answers", [])
        current_step_idx = state.get("step_idx", 0)
        
        # ì´ì „ì— ë°œê²¬í•œ ì¤‘ìš” ì •ë³´ ìˆ˜ì§‘
        found_entities = []
        found_facts = []
        promising_evidence = []
        
        for ans in progress:
            found_entities.append(ans["answer"])
            if ans.get("evidence"):
                for ev in ans["evidence"]:
                    if "located in" in ev or "published by" in ev or "founded in" in ev:
                        promising_evidence.append(ev)
        
        # í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘í•œ ëª¨ë“  ì¦ê±°ì—ì„œ ì¤‘ìš” ì •ë³´ ì¶”ì¶œ
        all_evidence = state.get("current_evidence", [])
        for ev in all_evidence:
            if any(keyword in ev.lower() for keyword in ["bronx", "botanical", "journal", "published"]):
                promising_evidence.append(ev)
        
        # ì‚¬ìš©ëœ ë¬¸ì„œ ì¤‘ ìœ ìš©í–ˆë˜ ê²ƒë“¤
        useful_docs = []
        failed_docs = state.get("failed_documents", {})
        for title, _ in state.get("hotpot_context", []):
            if title not in failed_docs.get(current_step_idx, []):
                # ë¬¸ì„œê°€ ì‹¤íŒ¨í•˜ì§€ ì•Šì•˜ê³ , ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìœ ìš©
                if any(keyword in title.lower() for keyword in ["journal", "botanical", "scientific"]):
                    useful_docs.append(title)
        
        #  ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
        failure_analysis = _analyze_failure_pattern(state, progress, all_evidence)
        
        #  ë™ì  ì „ëµ ìƒì„±
        dynamic_strategy = _generate_dynamic_strategy(
            question=state["question"],
            current_plan=state["plan"],
            stuck_step=current_step_idx,
            found_entities=found_entities,
            found_facts=found_facts,
            promising_evidence=promising_evidence,
            useful_docs=useful_docs,
            failure_analysis=failure_analysis,
            replan_count=replan_count,
            state = state
        )
        
        # í”„ë¡¬í”„íŠ¸ í•¨ìˆ˜ í˜¸ì¶œ
        REPLAN_PROMPT = get_replan_prompt(
            question=state["question"],
            plan_str=json.dumps(state["plan"], indent=2),
            current_step_idx=current_step_idx,
            progress_str=json.dumps([{"step": a["step"], "answer": a["answer"]} for a in progress], indent=2),
            found_entities_str=json.dumps(found_entities),
            promising_evidence_str=json.dumps(promising_evidence[:3]),
            useful_docs_str=json.dumps(useful_docs),
            failure_analysis=failure_analysis,
            dynamic_strategy=dynamic_strategy,
            replan_count=replan_count
        )
        
        out = call_llm(
            "You are a strategic replanner. Use found information, don't restart.",
            REPLAN_PROMPT,
            temperature=0.2
        )
        
        try:
            out_clean = out.strip()
            if out_clean.startswith("```"):
                lines = out_clean.split("\n")
                out_clean = "\n".join(lines[1:-1])
            
            j = json.loads(out_clean)
            new_plan = j.get("plan", state["plan"])
            
            #  ê¸°ì¡´ ì •ë³´ ë³´ì¡´í•˜ë©´ì„œ ê³„íš ì—…ë°ì´íŠ¸
            state["plan"] = new_plan
            state["step_idx"] = len(progress)  # ì™„ë£Œëœ stepë¶€í„° ì‹œì‘
            
            #  ì¤‘ìš”: ì°¾ì€ ì •ë³´ ë³´ì¡´
            state["preserved_findings"] = {
                "entities": found_entities,
                "facts": found_facts,
                "evidence": promising_evidence,
                "useful_docs": useful_docs
            }
            if "failed_documents" in state and state["step_idx"] in state["failed_documents"]:
                print(f"   ğŸ”„ [Planner] ìƒˆë¡œìš´ ì „ëµì„ ìœ„í•´ ì‹¤íŒ¨ ë¬¸ì„œ ê¸°ë¡ ì´ˆê¸°í™” (Step {state['step_idx'] + 1})")
                del state["failed_documents"][state['step_idx']]
            
            # retry ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
            state["retry_count"] = {}
            state["reasoner_request"] = ""
            
            print(f"\nâœ… ê³„íš ìˆ˜ì • (Step {state['step_idx'] + 1}ë¶€í„°):")
            print(f"   ğŸ“Œ ë³´ì¡´ëœ ì •ë³´: {len(found_entities)} entities, {len(promising_evidence)} evidence")
            for i, step in enumerate(new_plan, 1):
                marker = "âœ“" if i <= len(progress) else "â†’"
                print(f"   {marker} Step {i}: {step}")

        except Exception as e:
            print(f"   âš ï¸ ì¬ê³„íš ì‹¤íŒ¨: {e}")
            state["action"] = "finish"
            return state
        
        state["action"] = "reasoner"
        return state
    
    state["action"] = "reasoner"
    return state


def _analyze_failure_pattern(state: QAState, progress: list, evidence: list) -> str:
    """ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„"""
    
    retry_count = state.get("retry_count", {})
    step_idx = state.get("step_idx", 0)
    
    patterns = []
    
    # íŒ¨í„´ 1: ì •ë³´ê°€ ë¬¸ì„œì— ì—†ìŒ
    if all("does not provide" in str(ev).lower() for ev in evidence[-3:] if ev):
        patterns.append("Information not found in available documents")
    
    # íŒ¨í„´ 2: ì˜ëª»ëœ ë¬¸ì„œ ì„ íƒ
    if retry_count.get(f"step_{step_idx}", 0) > 5:
        patterns.append("Repeatedly selecting wrong documents")
    
    # íŒ¨í„´ 3: ì˜ì¡´ì„± ì²´ì¸ ê¹¨ì§
    if step_idx > 0 and not progress:
        patterns.append("Dependency chain broken - no previous results to build on")
    
    # íŒ¨í„´ 4: ë¶€ë¶„ ì •ë³´ë§Œ ìˆìŒ
    if progress and "partially" in str(progress[-1].get("answer", "")):
        patterns.append("Only partial information available")
    
    return "Failure patterns detected: " + ", ".join(patterns) if patterns else "No clear failure pattern"


def _generate_dynamic_strategy(
    question: str,
    current_plan: list,
    stuck_step: int,
    found_entities: list,
    found_facts: list,
    promising_evidence: list,
    useful_docs: list,
    failure_analysis: str,
    replan_count: int,
    state: QAState = None
) -> str:
    """ìƒí™©ì— ë§ëŠ” ë™ì  ì „ëµ ìƒì„±"""
    
    strategies = []
    
    # ì „ëµ 1: ì—”í‹°í‹° ê¸°ë°˜ ì ‘ê·¼
    if found_entities:
        entity_list = ", ".join(found_entities[:3])
        strategies.append(f"Search directly for information about these entities: {entity_list}")
    
    # ì „ëµ 2: ë¬¸ì„œ í™œìš©
    if useful_docs:
        doc_list = ", ".join(useful_docs[:3])
        strategies.append(f"Focus on these promising documents: {doc_list}")
    
    # ì „ëµ 3: ì—­ë°©í–¥ ì ‘ê·¼
    if "not found" in failure_analysis and replan_count == 0:
        strategies.append("Try REVERSE approach: start from the answer type and work backwards")
    
    # ì „ëµ 4: ë¶€ë¶„ ì •ë³´ í™œìš©
    if promising_evidence and replan_count == 1:
        strategies.append("Use partial information to approximate the answer")
    
    # ì „ëµ 5: í‚¤ì›Œë“œ ì¤‘ì‹¬
    keywords = _extract_keywords_hybrid(question, state)
    if keywords:
        strategies.append(f"Focus search on these key terms: {', '.join(keywords)}")
    
    return "\n".join(f"{i+1}. {s}" for i, s in enumerate(strategies))

def _extract_keywords_hybrid(question: str, state: QAState) -> list:
    """í•˜ì´ë¸Œë¦¬ë“œ í‚¤ì›Œë“œ ì¶”ì¶œ: ê·œì¹™ + ì»¨í…ìŠ¤íŠ¸"""
    
    keywords = set()
    
    # 1. ì •ê·œì‹ìœ¼ë¡œ ê¸°ë³¸ ì¶”ì¶œ
    # ê³ ìœ ëª…ì‚¬
    proper_nouns = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', question)
    keywords.update(proper_nouns)
    
    # ìˆ«ì
    numbers = re.findall(r'\b\d{4}\b', question)  # ë…„ë„
    keywords.update(numbers)
    
    # 2. ì´ë¯¸ ì°¾ì€ ì •ë³´ì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€
    if state.get("step_answers"):
        for ans in state["step_answers"]:
            # ë‹µë³€ì—ì„œ ëª…ì‚¬ ì¶”ì¶œ
            answer_words = ans["answer"].split()
            keywords.update([w for w in answer_words if w[0].isupper()])
    
    # 3. ë¬¸ì„œ ì œëª©ì—ì„œ íŒíŠ¸ ì–»ê¸°
    doc_titles = [title for title, _ in state.get("hotpot_context", [])]
    for title in doc_titles:
        # ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆëŠ” ë¬¸ì„œ ì œëª©ì˜ ë‹¨ì–´ë“¤
        title_words = title.split()
        for word in title_words:
            if word.lower() in question.lower():
                keywords.add(word)
    
    # 4. ì§ˆë¬¸ íƒ€ì…ë³„ í‚¤ì›Œë“œ
    question_lower = question.lower()
    if "when" in question_lower:
        keywords.add("year")
        keywords.add("date")
    elif "where" in question_lower:
        keywords.add("location")
        keywords.add("place")
    elif "who" in question_lower:
        keywords.add("person")
        keywords.add("name")
    
    return list(keywords)

# ==========================================
# [2] Reasoner Agent
# ==========================================
def node_reasoner(state: QAState) -> QAState:
    """
    Reasoner Agent: ì‹¤í–‰ ì œì–´ ë° Plannerì™€ í˜‘ë ¥
    """
    MAX_REPLANS = 2
    plan = state["plan"]
    step_idx = state["step_idx"]
    
    #  ì „ì²´ ë°˜ë³µ íšŸìˆ˜ ì¶”ì 
    total_iterations = state.get("total_iterations", 0) + 1
    state["total_iterations"] = total_iterations
    
    #  ì•ˆì „ì¥ì¹˜ 1: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    if total_iterations >= 40:  # 50 ì´ì „ì— ì¢…ë£Œ
        print(f"\nâš ï¸ [Reasoner] ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ({total_iterations})")
        print(f"   â†’ ë‹µë³€ ë¶ˆê°€ë¡œ ê°•ì œ ì¢…ë£Œ")
        
        # ì§€ê¸ˆê¹Œì§€ ëª¨ì€ ì •ë³´ë¡œ ë‹µë³€ ì‹œë„
        if state.get("step_answers"):
            state["action"] = "finish"
        else:
            # ì •ë³´ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ê¸°ë³¸ ë‹µë³€
            state["answer"] = "Unable to answer - information not found in context"
            state["action"] = "finish"
        return state
    
    #  ì¬ê³„íš íšŸìˆ˜ í™•ì¸
    replan_count = state.get("replan_count", 0)
    
    # ì¬ì‹œë„ í•œê³„
    retry_count = state.get("retry_count", {})
    step_key = f"step_{step_idx}"
    current_retry = retry_count.get(step_key, 0)
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ í™•ì¸
    failed_docs = state.get("failed_documents", {}).get(step_idx, [])
    total_docs = len(state.get("hotpot_context", []))
    remaining_docs = total_docs - len(failed_docs)
    
    #  ì¬ê³„íš ì¡°ê±´ ë° ì œí•œ
    should_replan = (current_retry >= 10) or (remaining_docs == 0 and current_retry >= 2)
    
    if should_replan:
        # ì¬ê³„íš í•œê³„ ë„ë‹¬ ì²´í¬
        if replan_count > MAX_REPLANS:
            print(f"\nâš ï¸ [Reasoner] ì¬ê³„íš í•œê³„ ë„ë‹¬ ({replan_count}/{MAX_REPLANS})")
            print(f"   â†’ ë¶€ë¶„ ì •ë³´ë¡œ ë‹µë³€ ì‹œë„")
            state["action"] = "finish"
            return state
        
        # 
        print(f"\nğŸ†˜ [Reasoner] Step {step_idx + 1} ë§‰í˜”ìŒ!")
        print(f"   Retry: {current_retry}, Remaining docs: {remaining_docs}")
        
        # 
        print(f"   ì¬ê³„íš íšŸìˆ˜: {replan_count }/{MAX_REPLANS}")
        print(f"   â†’ Plannerì—ê²Œ ì¬ê³„íš ìš”ì²­")
        
        state["reasoner_request"] = "replan"
        state["replan_count"] = replan_count + 1
        state["action"] = "planner"
        return state



    # ëª¨ë“  Step ì™„ë£Œ
    if step_idx >= len(plan):
        print(f"\n   âœ… All {len(plan)} steps completed")
        state["action"] = "finish"
        return state
    
    current_step = plan[step_idx]
    
    print(f"\nğŸ¤– [Reasoner] Step {step_idx+1}/{len(plan)} (Iteration {total_iterations})")
    print(f"   Goal: {current_step}")
    
    # Synthesis step ì²˜ë¦¬
    current_step_lower = current_step.lower()
    is_synthesis = (
        "from step 1 and 2" in current_step_lower or 
        "from step 1 and step 2" in current_step_lower or
        "from steps 1 and 2" in current_step_lower or
        "what they have in common" in current_step_lower or
        "determine if they were the same" in current_step_lower or
        "which was started first" in current_step_lower or
        "which came first" in current_step_lower
    )
    
    if is_synthesis:
        return _synthesize_step(state)
    
    # ì¦ê±° í™•ì¸
    evidence = state.get("current_evidence", [])
    
    if not evidence:
        print(f"   â†’ Searching...")
        state["action"] = "search"
        return state
    
    # "No relevant document" ë©”ì‹œì§€ í™•ì¸
    if evidence and "No relevant document found" in evidence[0]:
        print(f"   âš ï¸ Contextì— ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ")
        retry_count[step_key] = current_retry + 1
        state["retry_count"] = retry_count
        
        if current_retry >= 2:
            state["reasoner_request"] = "replan"
            state["replan_count"] = replan_count + 1  # ğŸ†•
            state["action"] = "planner"
            return state
        
        state["action"] = "search"
        return state
    
    # LLM ì¦ê±° ê²€ì¦
    is_sufficient = _verify_evidence_with_llm(current_step, evidence)
    
    if not is_sufficient:
        print(f"   â†’ Evidence insufficient")
        retry_count[step_key] = current_retry + 1
        state["retry_count"] = retry_count
        state["action"] = "search"
        return state
    
    # ë‹µë³€ ìƒì„±
    answer = _generate_step_answer(current_step, evidence)
    print(f"   âœ… Step Answer: {answer}")
    
    state.setdefault("step_answers", []).append({
        "step_idx": step_idx,
        "step": current_step,
        "answer": answer,
        "evidence": evidence
    })
    
    # ë‹¤ìŒ Step
    state["step_idx"] += 1
    state["current_evidence"] = []
    
    # ğŸ”§ ìˆ˜ì •: retry_count ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”
    if "retry_count" in state and step_key in state["retry_count"]:
        state["retry_count"].pop(step_key)
    
    # ë˜ëŠ” ë” ê°„ë‹¨í•˜ê²Œ:
    # state.setdefault("retry_count", {}).pop(step_key, None)
    
    if state["step_idx"] >= len(state["plan"]):
        state["action"] = "finish"
    else:
        state["action"] = "next_step"
    
    return state

# [2.1]
def _synthesize_step(state: QAState) -> QAState:
    """
    Synthesis step ì²˜ë¦¬ (ì¦ê±° í¬í•¨)
    """
    current_step = state["plan"][state["step_idx"]]
    prev_answers = state.get("step_answers", [])
    
    print(f"   â†’ Synthesis step")
    
    if len(prev_answers) < 2:
        print(f"   âš ï¸ Not enough previous answers for synthesis!")
        state["action"] = "search"
        return state
    
    # âœ… ì´ì „ ë‹µë³€ + ì¦ê±° ëª¨ë‘ í¬í•¨
    context_text = ""
    for a in prev_answers:
        context_text += f"\nStep {a['step_idx']+1}: {a['step']}\n"
        context_text += f"  Answer: {a['answer']}\n"
        if a.get('evidence'):
            context_text += f"  Evidence:\n"
            for ev in a['evidence'][:2]:  # ì¦ê±°ë„ í¬í•¨
                context_text += f"    - {ev}\n"
    # prompt func í˜¸ì¶œ
    PROMPT = get_synthesize_prompt(current_step, context_text)
    
    answer = call_llm(
        "You are a precise information synthesizer. Answer based ONLY on the evidence provided.",
        PROMPT,
        temperature=0.1
    )
    
    print(f"   âœ… Synthesized: {answer}")
    
    state.setdefault("step_answers", []).append({
        "step_idx": state["step_idx"],
        "step": current_step,
        "answer": answer,
        "evidence": []
    })
    
    state["step_idx"] += 1
    
    if state["step_idx"] >= len(state["plan"]):
        print(f"   â†’ Last step completed")
        state["action"] = "finish"
    else:
        state["action"] = "next_step"
    
    return state

# [2.2]
def _verify_evidence_with_llm(step: str, evidence: List[str]) -> bool:
    """
    LLMìœ¼ë¡œ ì¦ê±°ê°€ ì¶©ë¶„í•œì§€ íŒë‹¨ (ê°œì„ )
    """
    
    if not evidence:
        return False
    
    evidence_text = "\n".join([f"- {e}" for e in evidence])
    # prompt func í˜¸ì¶œ
    PROMPT = get_verify_evidence_prompt(step, evidence_text)

    try:
        result = call_llm(
            "You are a strict but fair evidence judge. Be lenient with partial information.",
            PROMPT,
            temperature=0.0
        ).strip().lower()
        
        print(f"   ğŸ” [LLM Judge] Evidence sufficient: {result}")
        
        return "yes" in result
        
    except Exception as e:
        print(f"   âš ï¸ [LLM Judge] Error: {e}, defaulting to True")
        return True  # Error ì‹œ ê´€ëŒ€í•˜ê²Œ

#[2.3]
def _generate_step_answer(step: str, evidence: List[str]) -> str:
    """
    ì¦ê±° ê¸°ë°˜ ë‹µë³€ ìƒì„± (ê°œì„ )
    """
    evidence_text = "\n".join(evidence)
    # prompt func í˜¸ì¶œ
    PROMPT = get_step_answer_prompt(step, evidence_text)

    return call_llm("You are a precise extractor.", PROMPT, temperature=0.1).strip()

# ==========================================
# [3] Searcher Agent
# ==========================================
# tool?
def node_searcher(state: QAState) -> QAState:
    """
    Tool: Contextì—ì„œ ë¬¸ì„œ ì„ íƒ (ì‚¬ìš©í•œ ë¬¸ì„œ ì œì™¸)
    """
    
    current_step = state["plan"][state["step_idx"]]
    context = state["hotpot_context"]
    step_idx = state["step_idx"]
    
    print(f"\nğŸ” [Searcher] Finding document for: {current_step}")
    
    #  ì´ë¯¸ ì‹¤íŒ¨í•œ ë¬¸ì„œë“¤ ê°€ì ¸ì˜¤ê¸°
    failed_docs = state.get("failed_documents", {}).get(step_idx, [])
    
    #  ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œë§Œ í•„í„°ë§
    available_context = [
        (title, sentences) 
        for title, sentences in context 
        if title not in failed_docs
    ]
    
    if not available_context:
        print(f"   âŒ ëª¨ë“  ë¬¸ì„œ ì‹œë„ ì™„ë£Œ, ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ ì—†ìŒ")
        state["current_evidence"] = ["No relevant document found in context"]
        state["action"] = "reasoner"
        return state
    
    print(f"   ğŸ“š ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ: {len(available_context)}/{len(context)}")
    
    # LLMìœ¼ë¡œ ë¬¸ì„œ ì„ íƒ
    selected_doc = _select_doc_with_llm(
        current_step, 
        available_context,  # ğŸ†• í•„í„°ë§ëœ ë¬¸ì„œë§Œ ì „ë‹¬
        state.get("step_answers", [])
    )   

    if not selected_doc:
        print(f"   âŒ No document found")
        state["action"] = "reasoner"
        return state
    
    title, sentences = selected_doc
    print(f"   âœ… Selected: {title}")
    
    #  ì‹¤íŒ¨í•œ ë¬¸ì„œë¡œ ê¸°ë¡ (ë‚˜ì¤‘ì— ì¬ì‹œë„ ì‹œ ì œì™¸)
    failed_docs_dict = state.get("failed_documents", {})
    if step_idx not in failed_docs_dict:
        failed_docs_dict[step_idx] = []
    failed_docs_dict[step_idx].append(title)
    state["failed_documents"] = failed_docs_dict
    
    state["current_doc"] = {
        "title": title,
        "text": " ".join(sentences)
    }
    
    state["action"] = "extract"
    
    return state

# [3.1]
def _select_doc_with_llm(
    step: str,
    context: List[Tuple[str, List[str]]],
    previous_answers: List[Dict]
) -> Optional[Tuple[str, List[str]]]:
    """
    LLMìœ¼ë¡œ ë¬¸ì„œ ì„ íƒ (ì´ì „ ë‹µë³€ í™œìš©)
    """
    
    if not context:
        return None
    
    titles = [title for title, _ in context]
    titles_str = "\n".join([f"{i+1}. {title}" for i, title in enumerate(titles)])
    
    # ğŸ†• ì´ì „ ë‹µë³€ ëª…ì‹œ
    prev_str = ""
    key_entities = []
    if previous_answers:
        prev_str = "\n\n**Previous findings:**\n"
        for a in previous_answers[-2:]:
            prev_str += f"- {a['step']}: {a['answer']}\n"
            key_entities.append(a['answer'])
    
    # ğŸ†• "from step X" ê°ì§€
    if ("from step" in step.lower() or "those" in step.lower() or 
        "these" in step.lower()) and key_entities:
        prev_str += f"\nğŸš¨ Current question refers to: {', '.join(key_entities)}\n"
        prev_str += f"Choose document most likely to have info about these entities!\n"
    # prompt func í˜¸ì¶œ
    PROMPT = get_select_doc_prompt(step, prev_str, titles_str, len(titles))
    
    try:
        result = call_llm(
            "You are a document selector who tracks entity references.",
            PROMPT,
            temperature=0.2
        ).strip()
        
        match = re.search(r'\d+', result)
        if match:
            doc_num = int(match.group()) - 1
            if 0 <= doc_num < len(context):
                return context[doc_num]
        
        print(f"   âš ï¸ Failed to parse, using first doc")
        return context[0] if context else None
        
    except Exception as e:
        print(f"   âŒ LLM error: {e}")
        return context[0] if context else None
    

# ==========================================
# [4] Extractor Agent
# ==========================================
def node_extractor(state: QAState) -> QAState:
    """
    Tool: ë¬¸ì„œì—ì„œ ì¦ê±° ì¶”ì¶œ (ì´ì „ step ë‹µë³€ í™œìš©)
    """
    
    current_step = state["plan"][state["step_idx"]]
    doc = state.get("current_doc", {})
    
    if not doc:
        print(f"\nğŸ“„ [Extractor] No document to extract from")
        state["action"] = "reasoner"
        return state
    
    print(f"\nğŸ“„ [Extractor] Extracting evidence")
    print(f"   From: {doc['title']}")
    
    # ğŸ†• ì´ì „ step ë‹µë³€ ëª…ì‹œì  ì²˜ë¦¬
    prev_answers = state.get("step_answers", [])
    prev_context = ""
    reference_entities = []  # ğŸ†• ì´ì „ ë‹µë³€ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ ì—”í‹°í‹°
    
    if prev_answers:
        prev_context = "\n\n**PREVIOUS FINDINGS (CRITICAL - USE THESE!):**\n"
        for i, a in enumerate(prev_answers[-3:], 1):
            prev_context += f"Step {a['step_idx']+1}: {a['step']}\n"
            prev_context += f"  â†’ Answer: {a['answer']}\n"
            
            # ğŸ†• ë‹µë³€ì—ì„œ í•µì‹¬ ì—”í‹°í‹° ì¶”ì¶œ
            reference_entities.append(a['answer'])
    
    # ğŸ†• "from step X" í‚¤ì›Œë“œ ê°ì§€
    references_prev_step = ("from step" in current_step.lower() or 
                           "those" in current_step.lower() or
                           "that" in current_step.lower() or
                           "these" in current_step.lower())
    
    reference_instruction = ""
    if references_prev_step and prev_answers:
        reference_instruction = f"""
ğŸš¨ **CRITICAL - REFERENCING PREVIOUS STEP:**
The current question uses "those/these/that/from step X" which refers to:
{chr(10).join([f"  - {ans}" for ans in reference_entities[-2:]])}

You MUST find information about THESE SPECIFIC entities mentioned above!
DO NOT find information about other entities in the document!

Example:
- Previous: "torpedo boats"
- Current: "objects carried by those ships"
- YOU MUST: Find what TORPEDO BOATS carry
- DO NOT: Find what other ships carry
"""
    task_text = f"Find information about: {', '.join(reference_entities[-2:])}" if references_prev_step and reference_entities else "Extract information that answers the current step"
    # prompt func í˜¸ì¶œ
    PROMPT = get_extractor_prompt(
        current_step=current_step,
        prev_context=prev_context,
        reference_instruction=reference_instruction,
        doc_title=doc['title'],
        doc_text=doc['text'][:1500],
        task_text=task_text
    )
    
    evidence = call_llm("You are a precise extractor who carefully tracks entity references across steps.", PROMPT, temperature=0.1).strip()
    print(f"   âœ… Evidence: {evidence[:100]}...")
    state.setdefault("current_evidence", []).append(evidence)
    state["action"] = "reasoner"
    return state
# ==========================================
# [5] Answer Agent
# ==========================================
# [5.1]
def _generate_final_answer(state: QAState) -> str:
    """
    ìµœì¢… ë‹µë³€ ìƒì„± (ì¦ê±° ìš°ì„  í™•ì¸)
    """
    question = state["question"]
    step_answers = state.get("step_answers", [])
    
    if not step_answers:
        return "Unable to answer - no information gathered"
    
    # ğŸ†• ì¦ê±° í¬í•¨
    steps_text = ""
    for i, ans in enumerate(step_answers, 1):
        steps_text += f"\nStep {i}: {ans['step']}\n"
        steps_text += f"  Answer: {ans['answer']}\n"
        
        # ğŸ†• ì¦ê±° ì¶”ê°€
        if ans.get('evidence'):
            steps_text += f"  ğŸ“„ Evidence:\n"
            for ev in ans['evidence'][:2]:  # ìµœëŒ€ 2ê°œ ì¦ê±°
                steps_text += f"    - {ev[:200]}...\n"
    # prompt func í˜¸ì¶œ
    PROMPT = get_final_answer_prompt(question, steps_text)
    
    response = call_llm(
        ANSWER_SYS,
        PROMPT,
        temperature=0.1
    )
    
    # JSON íŒŒì‹±
    try:
        response = response.strip()
        if response.startswith("```"):
            lines = response.split("\n")
            response = "\n".join(lines[1:-1])
        
        result = json.loads(response)
        final_answer = result.get("final_answer", "")
        
        print(f"\nğŸ¯ [Answer Generator]")
        print(f"   Question Type: {result.get('question_type', 'unknown')}")
        print(f"   Reasoning: {result.get('reasoning', 'N/A')[:100]}...")
        print(f"   Final Answer: {final_answer}")
        
        return final_answer
        
    except Exception as e:
        print(f"   âš ï¸ JSON parsing error: {e}")
        if step_answers:
            return step_answers[-1]["answer"]
        return "Unable to generate answer"

# [5]
def node_answer(state: QAState) -> QAState:
    """
    Answer Node: ìµœì¢… ë‹µë³€ ìƒì„± (ë‹¨ìˆœ ë³€í™˜)
    """
    print(f"\nğŸ¯ [Answer] Generating final answer")
    
    # ë‹¨ìˆœíˆ ìµœì¢… ë‹µë³€ë§Œ ìƒì„±
    final_answer = _generate_final_answer(state)
    
    print(f"    Final Answer: {final_answer}")
    
    state["answer"] = final_answer
    state["action"] = "finish"
    
    return state